{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import logging.config\n",
    "from configparser import ConfigParser\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as psf\n",
    "import subprocess\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.1.0,org.apache.spark:spark-sql-kafka-0-10_2.11:2.1.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": " Failed to find data source: kafka. Please deploy the application as per the deployment section of \"Structured Streaming + Kafka Integration Guide\".        ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/flynn/Documents/School/IS405.M21-BigData/test/test_spark_streaming.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flynn/Documents/School/IS405.M21-BigData/test/test_spark_streaming.ipynb#ch0000010?line=0'>1</a>\u001b[0m spark \u001b[39m=\u001b[39m SparkSession \\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flynn/Documents/School/IS405.M21-BigData/test/test_spark_streaming.ipynb#ch0000010?line=1'>2</a>\u001b[0m           \u001b[39m.\u001b[39mbuilder \\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flynn/Documents/School/IS405.M21-BigData/test/test_spark_streaming.ipynb#ch0000010?line=2'>3</a>\u001b[0m           \u001b[39m.\u001b[39mappName(\u001b[39m\"\u001b[39m\u001b[39mAPP\u001b[39m\u001b[39m\"\u001b[39m) \\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flynn/Documents/School/IS405.M21-BigData/test/test_spark_streaming.ipynb#ch0000010?line=3'>4</a>\u001b[0m           \u001b[39m.\u001b[39mgetOrCreate()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flynn/Documents/School/IS405.M21-BigData/test/test_spark_streaming.ipynb#ch0000010?line=5'>6</a>\u001b[0m df \u001b[39m=\u001b[39m spark\\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flynn/Documents/School/IS405.M21-BigData/test/test_spark_streaming.ipynb#ch0000010?line=6'>7</a>\u001b[0m       \u001b[39m.\u001b[39;49mreadStream \\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flynn/Documents/School/IS405.M21-BigData/test/test_spark_streaming.ipynb#ch0000010?line=7'>8</a>\u001b[0m       \u001b[39m.\u001b[39;49mformat(\u001b[39m\"\u001b[39;49m\u001b[39mkafka\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flynn/Documents/School/IS405.M21-BigData/test/test_spark_streaming.ipynb#ch0000010?line=8'>9</a>\u001b[0m       \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39mkafka.bootstrap.servers\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mlocalhost:9092\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/flynn/Documents/School/IS405.M21-BigData/test/test_spark_streaming.ipynb#ch0000010?line=9'>10</a>\u001b[0m       \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39msubscribe\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msparktest\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/flynn/Documents/School/IS405.M21-BigData/test/test_spark_streaming.ipynb#ch0000010?line=10'>11</a>\u001b[0m       \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39mstartingOffsets\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mearliest\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/flynn/Documents/School/IS405.M21-BigData/test/test_spark_streaming.ipynb#ch0000010?line=11'>12</a>\u001b[0m       \u001b[39m.\u001b[39;49mload()\n",
      "File \u001b[0;32m~/miniforge3/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/streaming.py:454\u001b[0m, in \u001b[0;36mDataStreamReader.load\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/streaming.py?line=451'>452</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jreader\u001b[39m.\u001b[39mload(path))\n\u001b[1;32m    <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/streaming.py?line=452'>453</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/streaming.py?line=453'>454</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jreader\u001b[39m.\u001b[39;49mload())\n",
      "File \u001b[0;32m~/miniforge3/envs/bigdata/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/py4j/java_gateway.py?line=1314'>1315</a>\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/py4j/java_gateway.py?line=1315'>1316</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/py4j/java_gateway.py?line=1316'>1317</a>\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/py4j/java_gateway.py?line=1317'>1318</a>\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/py4j/java_gateway.py?line=1319'>1320</a>\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/py4j/java_gateway.py?line=1320'>1321</a>\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/py4j/java_gateway.py?line=1321'>1322</a>\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/py4j/java_gateway.py?line=1323'>1324</a>\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/py4j/java_gateway.py?line=1324'>1325</a>\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/miniforge3/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/utils.py?line=112'>113</a>\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/utils.py?line=113'>114</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/utils.py?line=114'>115</a>\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/utils.py?line=115'>116</a>\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/utils.py?line=116'>117</a>\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/utils.py?line=117'>118</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/flynn/miniforge3/envs/bigdata/lib/python3.10/site-packages/pyspark/sql/utils.py?line=118'>119</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m:  Failed to find data source: kafka. Please deploy the application as per the deployment section of \"Structured Streaming + Kafka Integration Guide\".        "
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "          .builder \\\n",
    "          .appName(\"APP\") \\\n",
    "          .getOrCreate()\n",
    "\n",
    "df = spark\\\n",
    "      .readStream \\\n",
    "      .format(\"kafka\") \\\n",
    "      .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "      .option(\"subscribe\", \"sparktest\") \\\n",
    "      .option(\"startingOffsets\", \"earliest\") \\\n",
    "      .load()\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9985f58ef1190becec6469eb333007c8004df540712d1f3b3fef5db45f3fd0d1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('bigdata')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
